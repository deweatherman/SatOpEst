{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#import ftplib\n",
    "from dask.diagnostics import ProgressBar\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import datetime \n",
    "import time\n",
    "from datetime import datetime \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import scipy.stats as stats\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "##import sklearn\n",
    "#from sklearn.metrics import median_absolute_error, mean_squared_error,r2_score\n",
    "#from sklearn.linear_model import LinearRegression, RANSACRegressor, HuberRegressor\n",
    "\n",
    "\n",
    "import pyOptimalEstimation as pyOE\n",
    "\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "from cmocean import cm as cmo\n",
    "\n",
    "import matplotlib.ticker as mticker\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "from glob import glob\n",
    "\n",
    "#import imageio\n",
    "\n",
    "#from pathlib import Path\n",
    "\n",
    "#from netCDF4 import Dataset\n",
    "\n",
    "import gc, psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pyproj\n",
    "\n",
    "import pyresample\n",
    "from pyresample import create_area_def, load_area, data_reduce, utils, AreaDefinition\n",
    "from pyresample.geometry import SwathDefinition\n",
    "from pyresample.kd_tree import resample_nearest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sys.path.append('/nobackup/users/echeverr/Git/SatOpEst/support') # where supporting_routines_m live\n",
    "sys.path.append('/home/mario/Documents/work/code/git/SatOpEst/support') # where supporting_routines_m live\n",
    "\n",
    "import supporting_routines_m \n",
    "\n",
    "import os\n",
    "\n",
    "#rttov_installdir = '/usr/people/echeverr/Documents/code/nwpsaf/rttov13'\n",
    "rttov_installdir = '/home/mario/myLibs/rrtov13/rttov130'\n",
    "\n",
    "sys.path.append(rttov_installdir+'/wrapper')\n",
    "import pyrttov\n",
    "\n",
    "\n",
    "#current_directory = os.getcwd()\n",
    "#os.environ[\"CARTOPY_USER_BACKGROUNDS\"] = os.path.join(current_directory,'/nobackup/users/echeverr/py_tests/earthpy_example/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p = psutil.Process()\n",
    "\n",
    "#BT_dir = '/nobackup/users/echeverr/data/cmsaf/ssmis/F16/'\n",
    "BT_dir = '/home/mario/Data/CMSAF/ssims/F16/test_1ds/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BT_file = '*.nc'\n",
    "BT_file = 'BTRin20140909000000324SSF1601GL.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitions for the apriori means and covariances directories:\n",
    "\n",
    "#aprioLowCapDir = '/nobackup/users/echeverr/data/ECMWF_era5/SurfaceParamsEra5_2011_2014/log_gHum/lower_cap/'\n",
    "#aprioLowMidCapDir = '/nobackup/users/echeverr/data/ECMWF_era5/SurfaceParamsEra5_2011_2014/log_gHum/lowmid_cap/'\n",
    "#aprioUpMidCapDir = '/nobackup/users/echeverr/data/ECMWF_era5/SurfaceParamsEra5_2011_2014/log_gHum/upmid_cap/'\n",
    "#aprioUpCapDir = '/nobackup/users/echeverr/data/ECMWF_era5/SurfaceParamsEra5_2011_2014/log_gHum/upper_cap/'\n",
    "\n",
    "#aprioLowCapDir = '/home/mario/Data/Covariance_means/log_gHum/lower_cap/'\n",
    "#aprioLowMidCapDir = '/home/mario/Data/Covariance_means/log_gHum/lowmid_cap/'\n",
    "#aprioUpMidCapDir = '/home/mario/Data/Covariance_means/log_gHum/upmid_cap/'\n",
    "#aprioUpCapDir = '/home/mario/Data/Covariance_means/log_gHum/upper_cap/'\n",
    "\n",
    "aprioLowCapDir = '/home/mario/Data/Covariance_means/CDS_api_data/ERA5_data/lower_cap/'\n",
    "aprioLowMidCapDir = '/home/mario/Data/Covariance_means/CDS_api_data/ERA5_data/lowmid_cap/'\n",
    "aprioUpMidCapDir = '/home/mario/Data/Covariance_means/CDS_api_data/ERA5_data/upmid_cap/'\n",
    "aprioUpCapDir = '/home/mario/Data/Covariance_means/CDS_api_data/ERA5_data/upper_cap/'\n",
    "\n",
    "\n",
    "# list of directories contaning covariances and means; each dir contains one geographical zone \n",
    "# Geo. zones are divided in latitude strips: [-90,-40), [-40,0), [0,+40), [+40,+90]; lon. [-180,+180) for all\n",
    "dir_bands = [aprioLowCapDir,aprioLowMidCapDir,aprioUpMidCapDir,aprioUpCapDir] \n",
    "lat_bands = [[-90.0,-40.0],[-40.0,0.0],[0.0,40.0],[40.0,90.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Netcdf using xarray:\n",
    "def read_netcdfs(files, dim, transform_func=None, groups = None):\n",
    "    def process_one_path(path):\n",
    "        # use a context manager, to ensure the file gets closed after use\n",
    "        with xr.open_dataset(path, group = groups) as ds:\n",
    "            # transform_func should do some sort of selection or\n",
    "            # aggregation\n",
    "            if transform_func is not None:\n",
    "                ds = transform_func(ds)\n",
    "            # load all data from the transformed dataset, to ensure we can\n",
    "            # use it after closing each original file\n",
    "            ds.load()\n",
    "            return ds\n",
    "\n",
    "    paths = sorted(glob(files))\n",
    "    datasets = [process_one_path(p) for p in paths]\n",
    "    combined = xr.concat(datasets, dim)\n",
    "    return combined\n",
    "\n",
    "\n",
    "# returns the directory (str) corrisponding to the band where \"lat\" is located\n",
    "def get_band(lat,dir_bands,lat_bands):\n",
    "    i=0\n",
    "    for band in dir_bands: \n",
    "        if(np.logical_and(lat >= lat_bands[i][0], lat < lat_bands[i][1])):\n",
    "            band_out =band\n",
    "        i+=1\n",
    "    return band_out\n",
    "\n",
    "# Apply usual flags to CMSAF dataset (per scene)\n",
    "# Author: M. Echeverri, March 2021.\n",
    "# TODO:\n",
    "# - Add list of flags that the user wants to apply\n",
    "# - Add input checks\n",
    "\n",
    "def apply_scene_flags(scene_BT, BT_attributes):\n",
    "    \n",
    "    for i, scene in enumerate(scene_BT):\n",
    "        #scene_aux = scene\n",
    "        scene_aux = xr.where((scene.qc_fov==0), \n",
    "                                      scene, \n",
    "                                      np.nan)    # Apply 'qc_fov' flag \n",
    "        \n",
    "        scene_aux[\"tb\"] = xr.where((scene[\"tb\"]!=np.nan), \n",
    "                                      (scene[\"tb\"] + scene[\"ical\"]), \n",
    "                                          np.nan)  # Apply intercalibration offsets         \n",
    "\n",
    "        j = 0\n",
    "        for ch in scene.scene_channel.values:              # Apply 'qc_channel' flag \n",
    "            pos = (BT_attributes.qc_channel[:,scene.scene_channel[j]].values!=0)\n",
    "            scene_aux[\"tb\"][pos,j,:] = np.nan\n",
    "            j+=1\n",
    "\n",
    "        scene_BT[i] = scene_aux    \n",
    "    return scene_BT\n",
    "\n",
    "\n",
    "def apply_scene_flags1(scene_BT, BT_attributes):\n",
    "    \n",
    "    for i, scene in enumerate(scene_BT):\n",
    "        \n",
    "        scene_BT[i] = scene_BT[i].where(scene.qc_fov==0) # Apply 'qc_fov' flag \n",
    "        \n",
    "        # TODO: ical offsets are applied only to ssmis (they are all referenced to ssmi f11, I think, check)\n",
    "        attrs = scene_BT[i]['tb'].attrs\n",
    "        scene_BT[i]['tb'] = scene_BT[i].tb + scene_BT[i].ical # Apply intercalibration offsets         \n",
    "        attrs['long_name'] = 'brightness temperature after ical'\n",
    "        scene_BT[i]['tb'].attrs = attrs # keep attributes after ical   \n",
    "        \n",
    "        j = 0\n",
    "        for ch in scene.scene_channel.values:              # Apply 'qc_channel' flag \n",
    "            pos = (BT_attributes.qc_channel[:,scene.scene_channel[j]].values!=0)\n",
    "            scene_BT[i]['tb'].values[pos,j,:] = np.nan\n",
    "            j+=1\n",
    "        \n",
    "    return scene_BT\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def split_file_name(f):\n",
    "    aux1 = f.split(\".\")[0].split(\"0_\")\n",
    "    aux2 = aux1[1].split(\"_\")\n",
    "    season = aux1[0]\n",
    "    aORb = aux2[0]\n",
    "    meanORcov = aux2[1]\n",
    "    return season, aORb, meanORcov\n",
    "\n",
    "def get_mean_covs(directory,inputSeason):\n",
    "# very badly programed look-up table: it will look\n",
    "# for the files corrisponding to a given inputSeason \n",
    "# and return means and covariances for both state vector (a)\n",
    "# and parameters vector (b).\n",
    "    files = os.listdir(directory)\n",
    "    for f in files:\n",
    "        #print(f)\n",
    "        season, aORb, meanORcov = split_file_name(f)\n",
    "        if(inputSeason==season):\n",
    "            if(aORb=='a'):\n",
    "                if(meanORcov=='mean'):\n",
    "                    xa = pd.read_csv(directory+f, \n",
    "                                     index_col=0).rename_axis('state', \n",
    "                                                              axis=0).rename_axis('stateT', \n",
    "                                                                                  axis=1)\n",
    "                elif(meanORcov=='cov'):   \n",
    "                    Sa = pd.read_csv(directory+f, \n",
    "                                     index_col=0).rename_axis('state', \n",
    "                                                              axis=0).rename_axis('stateT', \n",
    "                                                                                  axis=1)\n",
    "                else:\n",
    "                    print('Something went wrong, check:')\n",
    "                    print(directory+f)\n",
    "            elif(aORb=='b'):\n",
    "                if(meanORcov=='mean'):\n",
    "                    xb = pd.read_csv(directory+f, \n",
    "                                     index_col=0).rename_axis('state', \n",
    "                                                              axis=0).rename_axis('stateT', \n",
    "                                                                                  axis=1)\n",
    "                elif(meanORcov=='cov'):   \n",
    "                    Sb = pd.read_csv(directory+f, \n",
    "                                     index_col=0).rename_axis('state', \n",
    "                                                              axis=0).rename_axis('stateT', \n",
    "                                                                                  axis=1)\n",
    "                else:\n",
    "                    print('Something went wrong, check:')\n",
    "                    print(directory+f)                \n",
    "            \n",
    "        \n",
    "    return xa,Sa,xb,Sb   \n",
    "\n",
    "def reshape4profiles(profiles):\n",
    "    # \"profiles\" is a numpy array\n",
    "    # \"profiles\" can contain 1 or more profiles\n",
    "    # \"profiles\" has dimensions (nlevels, nprofiles)\n",
    "    # \"outProfiles\" has dimensions (nprofiles,nlevels) (as needed in RTTOV)\n",
    "    \n",
    "    if (len(profiles.shape)==1):\n",
    "        outProfiles = profiles.reshape(1,profiles.shape[0]).copy()\n",
    "    else:\n",
    "        outProfiles = profiles.T.copy() #profiles.reshape(profiles.shape[1]\n",
    "            #                          ,profiles.shape[0]) \n",
    "    return outProfiles  \n",
    "\n",
    "def expand2nprofiles(n, nprof):\n",
    "    # Transform 1D array to a [nprof, nlevels] array\n",
    "    outp = np.empty((nprof, len(n)), dtype=n.dtype)\n",
    "    for i in range(nprof):\n",
    "        outp[i, :] = n[:]\n",
    "    return outp\n",
    "\n",
    "def forward_b_init(pressure, salinity, lat, long, datetime_obs64, \n",
    "                   zenithAngle, myProfiles):\n",
    "    \n",
    "    if (len(pressure.shape)==1):\n",
    "        nprofiles = 1\n",
    "    else:\n",
    "        nprofiles =  pressure.shape[1]\n",
    "    \n",
    "    # The rest of the code uses datetime64 format (numpy), but I have to pass the obs date as integers to RTTOV\n",
    "    datetime_obs = supporting_routines_m.datetime64_to_datetime(datetime_obs64)\n",
    "    \n",
    "    s2m = np.zeros((nprofiles,6), dtype=np.float64) # s2m has 6 elements (docs RTTOV)\n",
    "    \n",
    "    angles = np.zeros((nprofiles,4), dtype=np.float64) # angles has 4 elements (docs RTTOV)\n",
    "    angles[:,0] = zenithAngle\n",
    "    \n",
    "    \n",
    "    # for RTTOV 13 skin is 9 elements long:\n",
    "    skin = np.zeros((nprofiles,9), dtype=np.float64) # skin has 9 elements (docs RTTOV)\n",
    "    skin[:,1] = salinity\n",
    "        \n",
    "    surftype = np.zeros((nprofiles,2), dtype=np.int32) # surftype has 2 elements (docs RTTOV)\n",
    "    surftype[:,:] = 1 # [sea, ocean] Harcoded for now, TODO *** mario\n",
    "    \n",
    "    \n",
    "    surfgeom = np.zeros((nprofiles,3), dtype=np.float64) # surfgeom has 3 elements (docs RTTOV)\n",
    "    surfgeom[:,0] = lat\n",
    "    surfgeom[:,1] = long\n",
    "    # surfgeom[:,2]=0 # elevation harcoded to 0 for now, TODO *** mario\n",
    "    \n",
    "    date_times = np.zeros((nprofiles,6), dtype=np.int32) # date_times has 6 elements (docs RTTOV)\n",
    "    date_times[:,0] = datetime_obs.year\n",
    "    date_times[:,1] = datetime_obs.month\n",
    "    date_times[:,2] = datetime_obs.day\n",
    "    date_times[:,3] = datetime_obs.hour\n",
    "    date_times[:,4] = datetime_obs.minute\n",
    "    date_times[:,5] = datetime_obs.second\n",
    "    \n",
    "    \n",
    "    myProfiles.GasUnits = 1  # kg/kg (see RTTOV doc. for other options) # Harcoded for now, TODO *** mario\n",
    "    myProfiles.P = reshape4profiles(pressure) \n",
    "    myProfiles.S2m = s2m\n",
    "    myProfiles.Angles = angles\n",
    "    myProfiles.Skin = skin\n",
    "    myProfiles.SurfType = surftype\n",
    "    myProfiles.SurfGeom = surfgeom\n",
    "    myProfiles.DateTimes = date_times \n",
    "\n",
    "\n",
    "def forwardRT(X, myProfiles_a, ssmiRttov_a, channels_list=None):\n",
    "    \n",
    "    # TODO: Add assertions, tests *** mario\n",
    "\n",
    "    # X contains T, Q and W10, lets split the vector\n",
    "    #temperature, humidity, wind10m = supporting_routines_m.splitX(X)\n",
    "    \n",
    "    # if wind speed in components:\n",
    "\n",
    "    #temperature, humidity, u10m, v10m, bp2m, bt2m, btsk \\\n",
    "    #= supporting_routines_m.splitX_all(X)\n",
    "    \n",
    "    #NEW\n",
    "    # Wind u, v:\n",
    "    #temperature, humidity, u10m, v10m, t2m, tsk, sp \\\n",
    "    #= supporting_routines_m.splitX_all_2(X)\n",
    "    # Wind W:\n",
    "    temperature, humidity, w10m, t2m, tsk, sp \\\n",
    "    = supporting_routines_m.splitX_all_2W(X)    \n",
    "    \n",
    "    # humdity is in log10 scale, convert to linear in kg/kg\n",
    "    humidity = (10**humidity) / 1000.\n",
    "    # or abs_humidity? *** note mario\n",
    "\n",
    "    myProfiles_a.T = reshape4profiles(temperature.to_numpy(dtype=np.float64))  \n",
    "    myProfiles_a.Q = reshape4profiles(humidity.to_numpy(dtype=np.float64))  \n",
    "\n",
    "    myProfiles_a.S2m[:,0] = reshape4profiles(\n",
    "        sp.to_numpy(dtype=np.float64)).flatten() # surface pressure\n",
    "    myProfiles_a.S2m[:,1] = reshape4profiles(\n",
    "        t2m.to_numpy(dtype=np.float64)).flatten()  # 2m temperature\n",
    "    myProfiles_a.Skin[:,0] = reshape4profiles(\n",
    "        tsk.to_numpy(dtype=np.float64)).flatten() \n",
    "    \n",
    "    # if wind in components:\n",
    "    #myProfiles_a.S2m[:,3] = reshape4profiles(\n",
    "    #    u10m.to_numpy(dtype=np.float64)).flatten()  #  10m windspeed, u component\n",
    "    #myProfiles_a.S2m[:,4] = reshape4profiles(\n",
    "    #    v10m.to_numpy(dtype=np.float64)).flatten()  #  10m windspeed, v component \n",
    "    \n",
    "    # Wind W:\n",
    "    myProfiles_a.S2m[:,3] = 0.7071*reshape4profiles(\n",
    "        w10m.to_numpy(dtype=np.float64)).flatten()  #  10m windspeed\n",
    "    myProfiles_a.S2m[:,4] = myProfiles_a.S2m[:,3]    \n",
    "   \n",
    "    ssmiRttov_a.Profiles = myProfiles_a\n",
    "    \n",
    "    #ssmiRttov_a.SurfEmisRefl[:,:,:] = -1. # need to \"reset\" to -1 every time RTTOV is called; \n",
    "    # -1 indicates to RTTOV to use internal values for surface emissivity.\n",
    "\n",
    "    try:\n",
    "        ssmiRttov_a.runDirect(channels_list)\n",
    "    except pyrttov.RttovError as e:\n",
    "        sys.stderr.write(\"Error running RTTOV direct model: {!s}\".format(e))\n",
    "        sys.exit(1)    \n",
    "        \n",
    "    #print(ssmiRttov.BtRefl[:, :].shape)\n",
    "    #print(ssmiRttov.BtRefl[:, :])\n",
    "    \n",
    "    if(ssmiRttov_a.BtRefl[:, :].shape[0]==1):\n",
    "        TB = ssmiRttov_a.BtRefl[0, :].T\n",
    "    else:\n",
    "        TB = ssmiRttov_a.BtRefl[:, :].T\n",
    "    \n",
    "    return TB\n",
    "\n",
    "def rttovK(X, perturbation, y_var, myProfiles_a, ssmiRttov_a, channels_list=None):\n",
    "    \n",
    "    # TODO: Add assertions, tests *** mario\n",
    "\n",
    "    #temperature, humidity, u10m, v10m, t2m, tsk, sp \\\n",
    "    #= supporting_routines_m.splitX_all_2(X)\n",
    "\n",
    "    # Wind W:\n",
    "    temperature, humidity, w10m, t2m, tsk, sp \\\n",
    "    = supporting_routines_m.splitX_all_2W(X)        \n",
    "    \n",
    "    # humdity is in log10 scale, convert to linear in kg/kg\n",
    "    humidity = (10**humidity) / 1000.\n",
    "\n",
    "    myProfiles_a.T = reshape4profiles(temperature.to_numpy(dtype=np.float64))  \n",
    "    myProfiles_a.Q = reshape4profiles(humidity.to_numpy(dtype=np.float64))  \n",
    "\n",
    "    myProfiles_a.S2m[:,0] = reshape4profiles(\n",
    "        sp.to_numpy(dtype=np.float64)).flatten() # surface pressure\n",
    "    myProfiles_a.S2m[:,1] = reshape4profiles(\n",
    "        t2m.to_numpy(dtype=np.float64)).flatten()  # 2m temperature\n",
    "    myProfiles_a.Skin[:,0] = reshape4profiles(\n",
    "        tsk.to_numpy(dtype=np.float64)).flatten() \n",
    "    \n",
    "    # if wind in components:\n",
    "    #myProfiles_a.S2m[:,3] = reshape4profiles(\n",
    "    #    u10m.to_numpy(dtype=np.float64)).flatten()  #  10m windspeed, u component\n",
    "    #myProfiles_a.S2m[:,4] = reshape4profiles(\n",
    "    #    v10m.to_numpy(dtype=np.float64)).flatten()  #  10m windspeed, v component   \n",
    "    \n",
    "    # Wind W:\n",
    "    myProfiles_a.S2m[:,3] = 0.7071*reshape4profiles(\n",
    "        w10m.to_numpy(dtype=np.float64)).flatten()  #  10m windspeed\n",
    "    myProfiles_a.S2m[:,4] = myProfiles_a.S2m[:,3] \n",
    "    \n",
    "    ssmiRttov_a.Profiles = myProfiles_a\n",
    "    \n",
    "    #ssmiRttov_a.SurfEmisRefl[:,:,:] = -1. # need to \"reset\" to -1 every time RTTOV is called; \n",
    "    # -1 indicates to RTTOV to use internal values for surface emissivity.\n",
    "    \n",
    "    try:\n",
    "        ssmiRttov_a.runK(channels_list)\n",
    "    except pyrttov.RttovError as e:\n",
    "        sys.stderr.write(\"Error running RTTOV direct model: {!s}\".format(e))\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Create Jacobian Dataframe skeleton:\n",
    "    jacx = pd.DataFrame(index=y_var, columns=X.index)  \n",
    "    \n",
    "    # Fill-in Jacobian Dataframe\n",
    "    jacx = supporting_routines_m.mergeX_all_2W(jacx.T, X, \n",
    "                                            ssmiRttov_a,\n",
    "                                            perturbation = perturbation, \n",
    "                                            LogHum=True)\n",
    "\n",
    "    return jacx.T.to_numpy(dtype=np.float64) \n",
    "\n",
    "\n",
    "def sleep_and_print_mem(title, sleep=3):\n",
    "    time.sleep(sleep)\n",
    "    print(\"\\n\" + title + \" : \" +  \"%0.2f MB\" % (p.memory_info().rss / 1e6)\n",
    "         + \"   \" + \"=\" * 49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# here we suppose we only care about the combined mean of each file;\n",
    "# you might also use indexing operations like .sel to subset datasets\n",
    "BT_attributes = read_netcdfs(BT_dir+BT_file, dim='time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes_list = ['scene_env1'] #,'scene_img1','scene_img2','scene_las','scene_uas']\n",
    "\n",
    "scene_BT = []\n",
    "\n",
    "# BT_attributes.qc_scan can be applied at the moment of the retrieval?\n",
    "\n",
    "#for scene in scenes_list:        \n",
    "#    scene_BT.append(xr.open_mfdataset(\n",
    "#        BT_dir+BT_file, combine = 'nested', \n",
    "#        concat_dim='time', group = scene)) \n",
    "    \n",
    "# use 1 day dataset only:    \n",
    "for scene in scenes_list:        \n",
    "    scene_BT.append(xr.open_dataset(\n",
    "        BT_dir+BT_file, group = scene))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8284271247461903"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2/np.sin(np.pi/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE SCENE_HOMOGENIZATION (i.e. resample to unique or reference swath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.count_nonzero(BT_attributes.qc_scan==True)\n",
    "#aa = xr.open_dataset(BT_dir+'BTRin20140909000000324SSF1701GL.nc', group = 'scene_env1')\n",
    "#BT_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After all scenes are sampled on the same reference swath, we can concatenate the TB's\n",
    "# so we end up with a single dataset\n",
    "\n",
    "scene_BT_test = xr.concat(\n",
    "    apply_scene_flags1(scene_BT, BT_attributes),\n",
    "    dim='scene_channel').drop_vars(\n",
    "    ['laz','qc_fov','ical','eia_norm'])\n",
    "\n",
    "# Because of the way xarray.concat works \"scene_channel\" is introduced as dimension\n",
    "# in variables that do not depend on it (lat, lon, eia and sft); this is removed by\n",
    "# selecting only one \"scene_channel\" in each of those variables:\n",
    "scene_BT_test['lat'] = scene_BT_test.lat[0,:,:] #.copy()\n",
    "scene_BT_test['lon'] = scene_BT_test.lon[0,:,:] #.copy()\n",
    "scene_BT_test['eia'] = scene_BT_test.eia[0,:,:] #.copy()\n",
    "scene_BT_test['sft'] = scene_BT_test.sft[0,:,:] #.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final dataset where we remove the observations over land (where sft == 1):\n",
    "#DS_CMSAF = scene_BT_test.where(\n",
    "#    scene_BT_test.sft==0).dropna(dim='time',how='all').copy()\n",
    "\n",
    "#DS_CMSAF = scene_BT_test.assign_coords(\n",
    "#    time=(BT_attributes.time)).where(\n",
    "#    scene_BT_test.sft==0).dropna(\n",
    "#    dim='time',how='all') #.chunk({\"time\":100, \"scene_channel\":None, \"scene_across_track\":None}) #.copy()\n",
    "\n",
    "\n",
    "DS_CMSAF = scene_BT_test.assign_coords(\n",
    "    time=(BT_attributes.time)) #.where(\n",
    "#    scene_BT_test.sft==0).dropna(\n",
    "#    dim='time',how='all') #.chunk({\"time\":100, \"scene_channel\":None, \"scene_across_track\":None}) #.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_BT_test=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set knobs for use of OpenMP in RTTOV\n",
    "\n",
    "NthreadsF = 1  # Number of threads for forward model  #os.cpu_count()\n",
    "NthreadsFM = 4 # Number of threads for forward model (in case of multiple profiles, used in) #os.cpu_count()\n",
    "NprofsPerCallFM = 40 # ?Roughly speaking number of variables (e.g. 279) / Number of threads (e.g. 8)\n",
    "\n",
    "\n",
    "# Create instance of Profiles class; \n",
    "# it's a container of the input atmospheric state that RTTOV will simulate\n",
    "\n",
    "nprofiles = 1  # This is hardcoded (we use RTTOV within OE, workin on a single profile per OE)\n",
    "nlev = 37 # TODO: this needs to be read from the apriori data (covariances and means) \n",
    "myProfiles = pyrttov.Profiles(nprofiles, nlev)\n",
    "\n",
    "# Create instance of RTTOV\n",
    "ssmiRttov = pyrttov.Rttov()\n",
    "\n",
    "#chan_list_ssmi = (12,13,14,15,16,17,18) #(1,12,13,14,15,16) #  #\n",
    "\n",
    "# Define instrument (FileCoef):\n",
    "ssmiRttov.FileCoef = '{}/{}'.format(rttov_installdir,\n",
    "                                    \"rtcoef_rttov13/rttov7pred54L/rtcoef_dmsp_16_ssmis.dat\")\n",
    "\n",
    "# Load the instruments: for HIRS and MHS do not supply a channel list and\n",
    "# so read all channels\n",
    "try:\n",
    "    ssmiRttov.loadInst() #chan_list_ssmi\n",
    "except pyrttov.RttovError as e:\n",
    "    sys.stderr.write(\"Error loading instrument(s): {!s}\".format(e))\n",
    "    sys.exit(1)\n",
    "\n",
    "# Some settings\n",
    "ssmiRttov.Options.AddInterp = True\n",
    "#ssmiRttov.Options.InterpMode = 2\n",
    "ssmiRttov.Options.CO2Data = False\n",
    "ssmiRttov.Options.VerboseWrapper = False\n",
    "ssmiRttov.Options.DoCheckinput = False\n",
    "ssmiRttov.Options.UseQ2m = False\n",
    "ssmiRttov.Options.ApplyRegLimits = True\n",
    "ssmiRttov.Options.Verbose = False\n",
    "ssmiRttov.Options.FastemVersion = 6\n",
    "ssmiRttov.Options.Switchrad = True\n",
    "ssmiRttov.Options.Nthreads = NthreadsF\n",
    "\n",
    "# *********************************\n",
    "# *********************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY FOR MULTIPLE PROFILES CALL TESTING\n",
    "\n",
    "ssmiRttovM = pyrttov.Rttov()\n",
    "\n",
    "# SSMIS:\n",
    "\n",
    "ssmiRttovM.FileCoef = '{}/{}'.format(rttov_installdir,\n",
    "                                    \"rtcoef_rttov13/rttov7pred54L/rtcoef_dmsp_16_ssmis.dat\")\n",
    "\n",
    "ssmiRttovM.Options.AddInterp = True\n",
    "#ssmiRttovM.Options.InterpMode = 2\n",
    "ssmiRttovM.Options.CO2Data = False\n",
    "ssmiRttovM.Options.VerboseWrapper = False\n",
    "ssmiRttovM.Options.DoCheckinput = False\n",
    "ssmiRttovM.Options.UseQ2m = False\n",
    "ssmiRttovM.Options.ApplyRegLimits = True\n",
    "ssmiRttovM.Options.Verbose = False\n",
    "ssmiRttovM.Options.FastemVersion = 6 \n",
    "ssmiRttovM.Options.Nthreads = NthreadsFM\n",
    "#ssmiRttovM.Options.NprofsPerCall = NprofsPerCallFM\n",
    "ssmiRttovM.Options.Switchrad = True\n",
    "\n",
    "# Load the instruments: for HIRS and MHS do not supply a channel list and\n",
    "# so read all channels\n",
    "try:\n",
    "    ssmiRttovM.loadInst()\n",
    "except pyrttov.RttovError as e:\n",
    "    sys.stderr.write(\"Error loading instrument(s): {!s}\".format(e))\n",
    "    sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user input:\n",
    "init_date = np.datetime64('2014-09-09T00:25:00.000') \n",
    "end_date = np.datetime64('2014-09-09T00:30:00.000') \n",
    "\n",
    "# nearest to user input in dataset:\n",
    "init_date = DS_CMSAF.time.sel(time=init_date, method = \"nearest\")\n",
    "end_date = DS_CMSAF.time.sel(time=end_date, method = \"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = ((~np.isnan(DS_CMSAF.lat.sel(time=slice(init_date,end_date)).values))& # check for valid (lat,lon) (i.e. over the ocean) \n",
    "          (~np.isnan(DS_CMSAF.lon.sel(time=slice(init_date,end_date)).values)))\n",
    "total_count = int(aa.sum()/(90))\n",
    "total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aa.shape)\n",
    "print(DS_CMSAF.lat.sel(time=slice(init_date,end_date)).values[aa])\n",
    "print(DS_CMSAF.lon.sel(time=slice(init_date,end_date)).values[aa])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_wind = DS_CMSAF.sel(time=slice(init_date,end_date)).copy().drop_vars(['eia','sft','tb','scene_channel'])\n",
    "DS_wind['wind'] = xr.DataArray(\n",
    "                data   = np.full((DS_CMSAF.time.shape[0],DS_CMSAF.scene_across_track.shape[0]),np.nan),   # enter data here\n",
    "                dims   = ['time','scene_across_track'],\n",
    "                coords = {'time': DS_CMSAF.time, 'scene_across_track':DS_CMSAF.scene_across_track},\n",
    "                attrs  = {\n",
    "                    #'_FillValue': -999.9,\n",
    "                    'description': 'Near surface wind speed (NSWP)',\n",
    "                    'units'     : 'm/s'\n",
    "                    }\n",
    "                )\n",
    "DS_wind['wind_err'] = xr.DataArray(\n",
    "                data   = np.full((DS_CMSAF.time.shape[0],DS_CMSAF.scene_across_track.shape[0]),np.nan),   # enter data here\n",
    "                dims   = ['time','scene_across_track'],\n",
    "                coords = {'time': DS_CMSAF.time, 'scene_across_track':DS_CMSAF.scene_across_track},\n",
    "                attrs  = {\n",
    "                    #'_FillValue': -999.9,\n",
    "                    'description': 'NSWP uncertainty',\n",
    "                    'units'     : 'm/s'\n",
    "                    }\n",
    "                )\n",
    "\n",
    "DS_wind['chiSquareTest1'] = xr.DataArray(\n",
    "                data   = np.full((DS_CMSAF.time.shape[0],DS_CMSAF.scene_across_track.shape[0]),np.nan),   # enter data here\n",
    "                dims   = ['time','scene_across_track'],\n",
    "                coords = {'time': DS_CMSAF.time, 'scene_across_track':DS_CMSAF.scene_across_track},\n",
    "                attrs  = {\n",
    "                    #'_FillValue': -999.9,\n",
    "                    'description': 'Optimal solution agrees with observation in Y space',\n",
    "                    'units'     : 'True/False'\n",
    "                    }\n",
    "                )\n",
    "DS_wind['chiSquareTest2'] = xr.DataArray(\n",
    "                data   = np.full((DS_CMSAF.time.shape[0],DS_CMSAF.scene_across_track.shape[0]),np.nan),   # enter data here\n",
    "                dims   = ['time','scene_across_track'],\n",
    "                coords = {'time': DS_CMSAF.time, 'scene_across_track':DS_CMSAF.scene_across_track},\n",
    "                attrs  = {\n",
    "                    #'_FillValue': -999.9,\n",
    "                    'description': 'Observation agrees with prior in Y space',\n",
    "                    'units'     : 'True/False'\n",
    "                    }\n",
    "                )\n",
    "DS_wind['chiSquareTest3'] = xr.DataArray(\n",
    "                data   = np.full((DS_CMSAF.time.shape[0],DS_CMSAF.scene_across_track.shape[0]),np.nan),   # enter data here\n",
    "                dims   = ['time','scene_across_track'],\n",
    "                coords = {'time': DS_CMSAF.time, 'scene_across_track':DS_CMSAF.scene_across_track},\n",
    "                attrs  = {\n",
    "                    #'_FillValue': -999.9,\n",
    "                    'description': 'Optimal solution agrees with prior in Y space',\n",
    "                    'units'     : 'True/False'\n",
    "                    }\n",
    "                )\n",
    "DS_wind['chiSquareTest4'] = xr.DataArray(\n",
    "                data   = np.full((DS_CMSAF.time.shape[0],DS_CMSAF.scene_across_track.shape[0]),np.nan),   # enter data here\n",
    "                dims   = ['time','scene_across_track'],\n",
    "                coords = {'time': DS_CMSAF.time, 'scene_across_track':DS_CMSAF.scene_across_track},\n",
    "                attrs  = {\n",
    "                    #'_FillValue': -999.9,\n",
    "                    'description': 'Optimal solution agrees with priot in X space',\n",
    "                    'units'     : 'True/False'\n",
    "                    }\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('min lat')\n",
    "print(np.nanmin((DS_CMSAF.lat.sel(time=slice(init_date,end_date)).values)))\n",
    "print('max lat')\n",
    "print(np.nanmax((DS_CMSAF.lat.sel(time=slice(init_date,end_date)).values)))\n",
    "print('max lon')\n",
    "print(np.nanmax((DS_CMSAF.lon.sel(time=slice(init_date,end_date)).values)))\n",
    "print('min lon')\n",
    "print(np.nanmin((DS_CMSAF.lon.sel(time=slice(init_date,end_date)).values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add init function:\n",
    "\n",
    "def init_retrieval_data(nprofiles, time_i, lat, lon, \n",
    "                        channels_list, BT,\n",
    "                       dir_bands,lat_bands, \n",
    "                        zenithAngle, myProfiles,\n",
    "                       ssmiRttov, ssmiRttovM=None):   \n",
    "\n",
    "    adate = supporting_routines_m.datetime64_to_datetime(time_i)\n",
    "    season = supporting_routines_m.date2season(adate)\n",
    "    \n",
    "    # Load Atlases: (if any)    \n",
    "    #ssmiRttov.SurfEmisRefl = np.zeros((\n",
    "    #    4, nprofiles, len(channels_list)), dtype=np.float64)\n",
    "            \n",
    "    y_obs = pd.Series(BT,\n",
    "                index=channels_list\n",
    "                     )            \n",
    "            \n",
    "    # TODO Sy needs to be loaded from somewhere according to the channels_list: ***********\n",
    "            \n",
    "    # Channels 1-7, 12-16, 23, 24 (values from Deblonde-English 2003) (sigma or std)\n",
    "    y_noise = pd.Series(\n",
    "                    [\n",
    "                        2.4, 1.27, 1.44, 3.0, 1.34, 0.46, 0.47\n",
    "                    ],\n",
    "                    index=channels_list\n",
    "    )\n",
    "                            \n",
    "    # Variance values > std**2\n",
    "    S_y = pd.DataFrame(\n",
    "                np.diag(y_noise.values**2),\n",
    "                index=channels_list,\n",
    "                columns=channels_list,\n",
    "    )\n",
    "    # TODO Sy needs to be loaded from somewhere according to the channels_list  ***********\n",
    "            \n",
    "    datetime_obs = time_i #.values\n",
    "    salinity = 35 # hardcoded, not good; TODO Mario\n",
    "            \n",
    "    band = get_band(lat,dir_bands,lat_bands) # gets the directory for the band where 'lat' is located\n",
    "    xa,Sa,xb,Sb = get_mean_covs(band, season) # gets mean and covariances for the band and season\n",
    "            \n",
    "    # reverse order in x and S (profile variables are reordered from low pressure to high) \n",
    "    Sb = Sb.iloc[::-1,::-1]\n",
    "    Sa = Sa.iloc[::-1,::-1]\n",
    "    xb = xb.iloc[::-1].squeeze() # convert means from dataframe to series\n",
    "    xa = xa.iloc[::-1].squeeze()\n",
    "            \n",
    "    x_vars = xa.index.values\n",
    "    b_vars = xb.index.values\n",
    "            \n",
    "    # Get the pressure per level ; TODO: this needs to be independent of the variable (e.g. xb in this case)\n",
    "    xb_index = [float(i.split('_')[0]) for i in xb.index if i.endswith('temp')]\n",
    "    Pressure = np.array(xb_index).reshape(len(xb_index),1)\n",
    "                        \n",
    "    nlev = len([i for i in xb.index if i.endswith('temp')]) # number of levels in profile quantities\n",
    "\n",
    "\n",
    "    # forward_b_init fills \"myProfiles\" with the \"fixed\" parameters for the RTTOV simulation.\n",
    "    # The forward model F(x,b), RTTOV in our case, has two \"parameters\": x and b\n",
    "    # x is the state vector that is being retrieved (as such it is allowed to change during the retrieval)\n",
    "    # b contains all other parameters that are fixed during the retrieval (everything else that is not being retrieved)\n",
    "\n",
    "    forward_b_init(Pressure, salinity,\n",
    "                   lat, lon, datetime_obs, zenithAngle, myProfiles)\n",
    "    \n",
    "    # Define dictionary of parameters for the forward model:\n",
    "\n",
    "    forwardKwArgs = {\"myProfiles_a\" : myProfiles, \n",
    "                    \"ssmiRttov_a\" : ssmiRttov,\n",
    "                    \"channels_list\":channels_list.tolist()}    \n",
    "    \n",
    "\n",
    "    \n",
    "    # Define dictionary of parameters for the forward model (Multiple profiles case):\n",
    "    \n",
    "    if ssmiRttovM != None:   # if an RTTOV instance for multiple profiles has been defined\n",
    "        \n",
    "        # Initialize multiple profiles for using a single call to RTTOV\n",
    "        # This is to be passed to the Jacobian function inside pyOpEst:\n",
    "        # The Jacobian is needed per parameter (len(xa.index)+len(xb.index))\n",
    "\n",
    "        nProfilesM = len(xa.index)+len(xb.index) # total number of parameters (x and b)\n",
    "            \n",
    "        # Load Atlases for Multiple profiles: (if any)    \n",
    "        #ssmiRttovM.SurfEmisRefl = np.zeros((\n",
    "        #    4, nProfilesM, len(channels_list)), dtype=np.float64) # RTTOVv12 used (2,nprof,nchan)\n",
    "                   \n",
    "        myProfilesM = pyrttov.Profiles(nProfilesM, nlev) # \n",
    "\n",
    "        #press2 = np.ones((nlev, nProfilesM))*Pressure # Pressure:(nlev,1)\n",
    "      \n",
    "        # Initialize profile datastructure for use in Jacobian computation:        \n",
    "        forward_b_init(np.ones((nlev, nProfilesM))*Pressure, salinity,\n",
    "                       lat, lon, datetime_obs, zenithAngle, myProfilesM) \n",
    "    \n",
    "        forwardKwArgsM = {\"myProfiles_a\" : myProfilesM, \n",
    "        \"ssmiRttov_a\" : ssmiRttovM,\n",
    "        \"channels_list\":channels_list.tolist()}\n",
    "    else:\n",
    "        forwardKwArgsM = None    # if not, then use only the single profile RTTOV instance;\n",
    "                                 # this results in a much slower Jacobian calculation.\n",
    "        \n",
    "        \n",
    "    # Create OE object:\n",
    "    \n",
    "    oe_ref = pyOE.optimalEstimation( # oe_1 if windDisambiguation used\n",
    "        x_vars, # state variable names\n",
    "        xa,  # a priori\n",
    "        Sa, # a priori uncertainty\n",
    "        channels_list,  # measurement variable names\n",
    "        y_obs, # observations\n",
    "        S_y, # observation uncertainty\n",
    "        forwardRT, # forward Operator\n",
    "        userJacobian=rttovK, # RTTOV's K model operator\n",
    "        forwardKwArgs=forwardKwArgs, # additonal function arguments\n",
    "        multipleForwardKwArgs=forwardKwArgsM, # additonal function arguments for jacobian \n",
    "        #x_truth=x_truth, # true profile\n",
    "        b_vars=b_vars,   # Parameter vector variable names\n",
    "        b_p=xb,        # Parameter vector \n",
    "        S_b=Sb,        # Parameters error covariance matrix \n",
    "        disturbance=0.01\n",
    "    )\n",
    "    return oe_ref\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2 {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
       "Dimensions:             (time: 45505, scene_across_track: 90, scene_channel: 3)\n",
       "Coordinates:\n",
       "  * scene_across_track  (scene_across_track) int32 1 5 9 13 ... 345 349 353 357\n",
       "  * scene_channel       (scene_channel) int64 11 12 13\n",
       "  * time                (time) datetime64[ns] 2014-09-09 ... 2014-09-09T23:59:59\n",
       "Data variables:\n",
       "    lat                 (time, scene_across_track) float64 83.39 83.61 ... 46.99\n",
       "    lon                 (time, scene_across_track) float64 -114.1 ... 91.94\n",
       "    eia                 (time, scene_across_track) float32 53.81 53.81 ... 53.79\n",
       "    sft                 (time, scene_across_track) float32 11.0 11.0 ... 1.0 1.0\n",
       "    tb                  (time, scene_channel, scene_across_track) float32 197...\n",
       "Attributes:\n",
       "    title:                 Environmental Scene 1\n",
       "    comment:               feedhorn channels: h19, v19, v22\n",
       "    elevation_offset_deg:  0.4\n",
       "    azimuth_offset_deg:    -0.3</pre><div class='xr-wrap' hidden><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-58051069-4623-4633-a8cb-efac7cd34807' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-58051069-4623-4633-a8cb-efac7cd34807' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>time</span>: 45505</li><li><span class='xr-has-index'>scene_across_track</span>: 90</li><li><span class='xr-has-index'>scene_channel</span>: 3</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-91793a60-b0f8-4be2-afbb-8fbb8da2dce3' class='xr-section-summary-in' type='checkbox'  checked><label for='section-91793a60-b0f8-4be2-afbb-8fbb8da2dce3' class='xr-section-summary' >Coordinates: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>scene_across_track</span></div><div class='xr-var-dims'>(scene_across_track)</div><div class='xr-var-dtype'>int32</div><div class='xr-var-preview xr-preview'>1 5 9 13 17 ... 341 345 349 353 357</div><input id='attrs-b6e66000-2333-444a-96ad-2f157f0510c3' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-b6e66000-2333-444a-96ad-2f157f0510c3' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-26fa914a-8284-44ca-b0b3-37c0fba85693' class='xr-var-data-in' type='checkbox'><label for='data-26fa914a-8284-44ca-b0b3-37c0fba85693' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>compress :</span></dt><dd>across_track</dd><dt><span>long_name :</span></dt><dd>scene across track position index</dd></dl></div><div class='xr-var-data'><pre>array([  1,   5,   9,  13,  17,  21,  25,  29,  33,  37,  41,  45,  49,  53,\n",
       "        57,  61,  65,  69,  73,  77,  81,  85,  89,  93,  97, 101, 105, 109,\n",
       "       113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165,\n",
       "       169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221,\n",
       "       225, 229, 233, 237, 241, 245, 249, 253, 257, 261, 265, 269, 273, 277,\n",
       "       281, 285, 289, 293, 297, 301, 305, 309, 313, 317, 321, 325, 329, 333,\n",
       "       337, 341, 345, 349, 353, 357], dtype=int32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>scene_channel</span></div><div class='xr-var-dims'>(scene_channel)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>11 12 13</div><input id='attrs-df80637e-197c-40a9-a33c-9bfff4e73330' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-df80637e-197c-40a9-a33c-9bfff4e73330' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-7081c64e-8a7c-4f12-a968-2dec41eeb54f' class='xr-var-data-in' type='checkbox'><label for='data-7081c64e-8a7c-4f12-a968-2dec41eeb54f' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>compress :</span></dt><dd>channel</dd><dt><span>long_name :</span></dt><dd>scene channel number index</dd></dl></div><div class='xr-var-data'><pre>array([11, 12, 13])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>2014-09-09 ... 2014-09-09T23:59:59</div><input id='attrs-0cddbc30-8678-4958-8bab-c896344c794a' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-0cddbc30-8678-4958-8bab-c896344c794a' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-ca1daaec-a869-4aca-942e-953b8160a65c' class='xr-var-data-in' type='checkbox'><label for='data-ca1daaec-a869-4aca-942e-953b8160a65c' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>scan start time</dd><dt><span>standard_name :</span></dt><dd>time</dd><dt><span>axis :</span></dt><dd>T</dd><dt><span>C_format :</span></dt><dd>%15d</dd><dt><span>FORTRAN_format :</span></dt><dd>I15</dd></dl></div><div class='xr-var-data'><pre>array([&#x27;2014-09-09T00:00:00.000000000&#x27;, &#x27;2014-09-09T00:00:02.000000000&#x27;,\n",
       "       &#x27;2014-09-09T00:00:04.000000000&#x27;, ..., &#x27;2014-09-09T23:59:55.000000000&#x27;,\n",
       "       &#x27;2014-09-09T23:59:57.000000000&#x27;, &#x27;2014-09-09T23:59:59.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-11633dd6-08e5-406d-ab9b-636213207166' class='xr-section-summary-in' type='checkbox'  checked><label for='section-11633dd6-08e5-406d-ab9b-636213207166' class='xr-section-summary' >Data variables: <span>(5)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>lat</span></div><div class='xr-var-dims'>(time, scene_across_track)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>83.39 83.61 83.82 ... 46.82 46.99</div><input id='attrs-d0a8fa08-58ad-4873-9ead-2537c4ef8e6e' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-d0a8fa08-58ad-4873-9ead-2537c4ef8e6e' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-878a4520-af53-4649-bc21-b587519acec4' class='xr-var-data-in' type='checkbox'><label for='data-878a4520-af53-4649-bc21-b587519acec4' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>latitude</dd><dt><span>standard_name :</span></dt><dd>latitude</dd><dt><span>units :</span></dt><dd>degree_north</dd><dt><span>valid_min :</span></dt><dd>-90.0</dd><dt><span>valid_max :</span></dt><dd>90.0</dd><dt><span>C_format :</span></dt><dd>%11.3f</dd><dt><span>FORTRAN_format :</span></dt><dd>F11.3</dd></dl></div><div class='xr-var-data'><pre>array([[83.395, 83.609, 83.818, ..., 72.673, 72.515, 72.359],\n",
       "       [83.505, 83.719, 83.928, ..., 72.71 , 72.552, 72.398],\n",
       "       [83.615, 83.829, 84.037, ..., 72.746, 72.59 , 72.436],\n",
       "       ...,\n",
       "       [51.197, 50.97 , 50.745, ..., 46.855, 47.022, 47.193],\n",
       "       [51.086, 50.86 , 50.635, ..., 46.751, 46.919, 47.09 ],\n",
       "       [50.976, 50.749, 50.524, ..., 46.648, 46.816, 46.987]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>lon</span></div><div class='xr-var-dims'>(time, scene_across_track)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>-114.1 -114.9 ... 91.71 91.94</div><input id='attrs-2dda54df-1562-46f5-8e59-58d68e62994b' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-2dda54df-1562-46f5-8e59-58d68e62994b' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-6ee0ec00-8273-469d-ac52-6f7bdd2e9047' class='xr-var-data-in' type='checkbox'><label for='data-6ee0ec00-8273-469d-ac52-6f7bdd2e9047' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>longitude</dd><dt><span>standard_name :</span></dt><dd>longitude</dd><dt><span>units :</span></dt><dd>degree_east</dd><dt><span>valid_min :</span></dt><dd>-180.0</dd><dt><span>valid_max :</span></dt><dd>180.0</dd><dt><span>C_format :</span></dt><dd>%11.3f</dd><dt><span>FORTRAN_format :</span></dt><dd>F11.3</dd></dl></div><div class='xr-var-data'><pre>array([[-114.075, -114.932, -115.902, ..., -179.795, -179.221, -178.643],\n",
       "       [-114.177, -115.052, -116.042, ...,  179.846, -179.575, -178.992],\n",
       "       [-114.282, -115.176, -116.188, ...,  179.487, -179.93 , -179.343],\n",
       "       ...,\n",
       "       [  68.477,   68.57 ,   68.672, ...,   91.604,   91.842,   92.075],\n",
       "       [  68.457,   68.55 ,   68.652, ...,   91.537,   91.774,   92.006],\n",
       "       [  68.438,   68.531,   68.632, ...,   91.47 ,   91.707,   91.938]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>eia</span></div><div class='xr-var-dims'>(time, scene_across_track)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>53.81 53.81 53.81 ... 53.79 53.79</div><input id='attrs-f1e221d1-b5e6-41e3-b5c1-5db8cd64deca' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-f1e221d1-b5e6-41e3-b5c1-5db8cd64deca' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-c67bc12f-6d95-4196-bffd-0a5ba5d4c705' class='xr-var-data-in' type='checkbox'><label for='data-c67bc12f-6d95-4196-bffd-0a5ba5d4c705' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>earth incidence angle</dd><dt><span>standard_name :</span></dt><dd>angle_of_incidence</dd><dt><span>units :</span></dt><dd>degree</dd><dt><span>C_format :</span></dt><dd>%6.3f</dd><dt><span>FORTRAN_format :</span></dt><dd>F6.3</dd></dl></div><div class='xr-var-data'><pre>array([[53.813, 53.813, 53.813, ..., 53.814, 53.815, 53.815],\n",
       "       [53.813, 53.813, 53.813, ..., 53.814, 53.815, 53.815],\n",
       "       [53.813, 53.813, 53.813, ..., 53.814, 53.815, 53.815],\n",
       "       ...,\n",
       "       [53.776, 53.776, 53.776, ..., 53.788, 53.787, 53.786],\n",
       "       [53.776, 53.776, 53.776, ..., 53.788, 53.787, 53.786],\n",
       "       [53.775, 53.776, 53.776, ..., 53.788, 53.787, 53.786]],\n",
       "      dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>sft</span></div><div class='xr-var-dims'>(time, scene_across_track)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>11.0 11.0 11.0 11.0 ... 1.0 1.0 1.0</div><input id='attrs-40b6a9cd-06c6-44be-b74f-2e6e3e51293d' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-40b6a9cd-06c6-44be-b74f-2e6e3e51293d' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-0ac3495e-97be-4f45-b3ee-46650697548d' class='xr-var-data-in' type='checkbox'><label for='data-0ac3495e-97be-4f45-b3ee-46650697548d' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>surface type</dd><dt><span>units :</span></dt><dd>1</dd><dt><span>C_format :</span></dt><dd>%3d</dd><dt><span>FORTRAN_format :</span></dt><dd>I3</dd><dt><span>flag_values :</span></dt><dd>[ 0  1  2  3 11 12]</dd><dt><span>flag_meanings :</span></dt><dd>water land coast coast2 sea_ice sea_ice_edge</dd></dl></div><div class='xr-var-data'><pre>array([[11., 11., 11., ..., 12., 12., 12.],\n",
       "       [11., 11., 11., ..., 12., 11., 12.],\n",
       "       [11., 11., 11., ..., 12., 11., 12.],\n",
       "       ...,\n",
       "       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1., ...,  1.,  1.,  1.]], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>tb</span></div><div class='xr-var-dims'>(time, scene_channel, scene_across_track)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>197.3 198.1 197.2 ... 260.6 261.4</div><input id='attrs-663d6617-f5d4-4372-97d8-4ff005681dd6' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-663d6617-f5d4-4372-97d8-4ff005681dd6' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-18a4c2fc-c236-44a8-a5e0-1a7421e10996' class='xr-var-data-in' type='checkbox'><label for='data-18a4c2fc-c236-44a8-a5e0-1a7421e10996' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>brightness temperature after ical</dd><dt><span>standard_name :</span></dt><dd>brightness_temperature</dd><dt><span>units :</span></dt><dd>K</dd><dt><span>C_format :</span></dt><dd>%6.2f</dd><dt><span>FORTRAN_format :</span></dt><dd>F6.2</dd></dl></div><div class='xr-var-data'><pre>array([[[197.27    , 198.14    , 197.21    , ..., 106.579994,\n",
       "         104.85    , 105.61    ],\n",
       "        [221.41    , 221.61    , 220.32    , ..., 182.93001 ,\n",
       "         182.36    , 181.94    ],\n",
       "        [220.93001 , 220.56001 , 220.      , ..., 195.08    ,\n",
       "         193.70001 , 193.19    ]],\n",
       "\n",
       "       [[198.04    , 198.05    , 196.59    , ..., 107.81    ,\n",
       "         105.39    , 104.52    ],\n",
       "        [220.73001 , 220.78    , 219.76    , ..., 183.04001 ,\n",
       "         183.09001 , 182.      ],\n",
       "        [220.69    , 220.58    , 219.71    , ..., 195.04001 ,\n",
       "         193.6     , 192.94    ]],\n",
       "\n",
       "       [[198.20999 , 197.6     , 195.87    , ..., 108.89    ,\n",
       "         106.649994, 104.32    ],\n",
       "        [221.11    , 221.16    , 220.23999 , ..., 184.75    ,\n",
       "         183.25    , 181.93    ],\n",
       "        [221.04001 , 219.46    , 218.41    , ..., 196.11    ,\n",
       "         193.91    , 192.77    ]],\n",
       "...\n",
       "       [[259.99    , 257.78    , 253.66    , ..., 251.81    ,\n",
       "         250.58    , 252.56    ],\n",
       "        [270.37    , 268.87    , 267.32    , ..., 262.41    ,\n",
       "         262.34003 , 265.16    ],\n",
       "        [268.98    , 267.94    , 266.06    , ..., 261.13    ,\n",
       "         260.88    , 264.56    ]],\n",
       "\n",
       "       [[258.53    , 256.86    , 248.22    , ..., 253.19    ,\n",
       "         251.23    , 250.98    ],\n",
       "        [270.07    , 269.16    , 265.09    , ..., 263.35    ,\n",
       "         261.59    , 263.84    ],\n",
       "        [269.15002 , 267.63    , 264.4     , ..., 261.59    ,\n",
       "         260.34    , 262.92    ]],\n",
       "\n",
       "       [[257.4     , 255.12    , 242.61    , ..., 254.17    ,\n",
       "         251.15    , 250.92    ],\n",
       "        [269.53    , 268.74002 , 261.59    , ..., 262.97    ,\n",
       "         262.08002 , 262.61002 ],\n",
       "        [268.17    , 267.      , 261.55    , ..., 262.16998 ,\n",
       "         260.62003 , 261.37003 ]]], dtype=float32)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-1112d613-a273-444e-908a-2d3e91b84c7b' class='xr-section-summary-in' type='checkbox'  checked><label for='section-1112d613-a273-444e-908a-2d3e91b84c7b' class='xr-section-summary' >Attributes: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>title :</span></dt><dd>Environmental Scene 1</dd><dt><span>comment :</span></dt><dd>feedhorn channels: h19, v19, v22</dd><dt><span>elevation_offset_deg :</span></dt><dd>0.4</dd><dt><span>azimuth_offset_deg :</span></dt><dd>-0.3</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:             (time: 45505, scene_across_track: 90, scene_channel: 3)\n",
       "Coordinates:\n",
       "  * scene_across_track  (scene_across_track) int32 1 5 9 13 ... 345 349 353 357\n",
       "  * scene_channel       (scene_channel) int64 11 12 13\n",
       "  * time                (time) datetime64[ns] 2014-09-09 ... 2014-09-09T23:59:59\n",
       "Data variables:\n",
       "    lat                 (time, scene_across_track) float64 83.39 83.61 ... 46.99\n",
       "    lon                 (time, scene_across_track) float64 -114.1 ... 91.94\n",
       "    eia                 (time, scene_across_track) float32 53.81 53.81 ... 53.79\n",
       "    sft                 (time, scene_across_track) float32 11.0 11.0 ... 1.0 1.0\n",
       "    tb                  (time, scene_channel, scene_across_track) float32 197...\n",
       "Attributes:\n",
       "    title:                 Environmental Scene 1\n",
       "    comment:               feedhorn channels: h19, v19, v22\n",
       "    elevation_offset_deg:  0.4\n",
       "    azimuth_offset_deg:    -0.3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DS_CMSAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>eia</th>\n",
       "      <th>sft</th>\n",
       "      <th>tb</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scene_channel</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9.248</td>\n",
       "      <td>57.542</td>\n",
       "      <td>53.759998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161.830002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9.248</td>\n",
       "      <td>57.542</td>\n",
       "      <td>53.759998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.040009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9.248</td>\n",
       "      <td>57.542</td>\n",
       "      <td>53.759998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>252.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 lat     lon        eia  sft          tb\n",
       "scene_channel                                           \n",
       "11             9.248  57.542  53.759998  0.0  161.830002\n",
       "12             9.248  57.542  53.759998  0.0  216.040009\n",
       "13             9.248  57.542  53.759998  0.0  252.750000"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DS_CMSAF.sel(time=slice(init_date,end_date)).stack(\n",
    "            index=('time','scene_across_track')).to_dataframe().loc[\"2014-09-09 00:25:00\",1] \n",
    "            #.unstack()   #\\\n",
    "              #to_dataframe(dim_order=['time','scene_across_track','scene_channel']).\\\n",
    "              #iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped=DS_CMSAF.sel(time=slice(init_date,end_date)).\\\n",
    "              to_dataframe(dim_order=['time','scene_across_track','scene_channel']).\\\n",
    "              groupby([\"time\",\"scene_across_track\"]) #.iloc[0:10] \n",
    "\n",
    "for group_name, group in grouped:\n",
    "    print(group_name)\n",
    "    print(group) #.reset_index(level=['lat','lon'])\n",
    "              #to_dask_dataframe(dim_order=['time','scene_across_track','scene_channel']).\\\n",
    "              #compute().iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sleep_and_print_mem(\"Initial memory\")            \n",
    "\n",
    "startTimeAll = time.time()\n",
    "\n",
    "# Main cycle: loop through locations in the swath\n",
    "count = 0\n",
    "#for time in DS_CMSAF.time.loc[init_date:end_date]: #DS_CMSAF.time[0:3]:\n",
    "\n",
    "i = 0\n",
    "\n",
    "for time_i in DS_CMSAF.time.sel(time=slice(init_date,end_date)): #DS_CMSAF.time[0:3]:\n",
    "    adate = supporting_routines_m.datetime64_to_datetime(time_i.values)\n",
    "    season = supporting_routines_m.date2season(adate)\n",
    "    \n",
    "    for acrossT in DS_CMSAF.scene_across_track[0:90]:\n",
    "        \n",
    "        if(DS_CMSAF.sft.loc[time_i,acrossT].values==0):\n",
    "        \n",
    "        #if(~np.isnan(DS_CMSAF.lat.loc[time_i,acrossT].values)& # check for valid (lat,lon) (i.e. over the ocean) \n",
    "        #  ~np.isnan(DS_CMSAF.lon.loc[time_i,acrossT].values)):\n",
    "                   \n",
    "                \n",
    "            startTimeRest = time.time()\n",
    "            \n",
    "            i+=1    \n",
    "                \n",
    "            startTimeGetVars = time.time() \n",
    "            \n",
    "            lat = DS_CMSAF.lat.loc[\n",
    "                time_i,acrossT].values.item() # expected to be a scalar; TODO add check\n",
    "            lon = DS_CMSAF.lon.loc[\n",
    "                time_i,acrossT].values.item() # expected to be a scalar; TODO add check\n",
    "            \n",
    "            #  TODO add checks on shapes or sizes of the next 3 arrays:\n",
    "            valid_channels = np.where(~np.isnan(  # not nan channels only\n",
    "                DS_CMSAF.tb.loc[time_i,:,acrossT].values))\n",
    "            \n",
    "            channels_list =  BT_attributes.channel[ # global channels ID's\n",
    "                DS_CMSAF.scene_channel.values[valid_channels]].values[0:7] # TODO: [0:7] is hardcoded, not good\n",
    "            \n",
    "            \n",
    "            BT = DS_CMSAF.tb.loc[ # Brightness Temps. for valid channels\n",
    "                time_i,DS_CMSAF.scene_channel.values[\n",
    "                    valid_channels],acrossT].values[0:7]  # TODO: [0:7] is hardcoded, not good\n",
    "\n",
    "            zenithAngle = DS_CMSAF.eia.loc[\n",
    "                time_i,acrossT].values.item() # expected to be a scalar; TODO add check\n",
    "            \n",
    "            print(\"%.2f s , TimeGetVars\" % (time.time()-startTimeGetVars))\n",
    "\n",
    "            startTimeInitialize = time.time()\n",
    "            \n",
    "            oe_ref = init_retrieval_data(nprofiles, time_i.values, \n",
    "                                         lat, lon,\n",
    "                                         channels_list, BT,\n",
    "                                         dir_bands,lat_bands,\n",
    "                                         zenithAngle, myProfiles,\n",
    "                                         ssmiRttov, ssmiRttovM)\n",
    "            \n",
    "            print(\"%.2f s , TimeInitialize\" % (time.time()-startTimeInitialize))\n",
    "\n",
    "            count +=1\n",
    "            print(str(count)+' out of '+str(total_count))\n",
    "            \n",
    "            oe_ref.doRetrieval()     \n",
    "            \n",
    "            if not oe_ref.converged :  # \n",
    "                DS_wind['wind'].loc[time_i,acrossT] = np.nan\n",
    "                DS_wind['wind_err'].loc[time_i,acrossT] = np.nan\n",
    "                #print(y_obs)\n",
    "                #print(band)\n",
    "                #print(lat)\n",
    "                #print(lon)\n",
    "                \n",
    "                continue            \n",
    "            \n",
    "            #_, _, u10m, v10m, _, tsk,_ = supporting_routines_m.splitX_all_2(oe_ref.x_op)\n",
    "            #_, _, u10m_err, v10m_err, _, tsk_err,_ = supporting_routines_m.splitX_all_2(oe_ref.x_op_err)\n",
    "            \n",
    "            #w10m, w10m_err = supporting_routines_m.UV2Wvar(oe_ref.S_op.loc['00000_u10','00000_u10'],\n",
    "            #                                      oe_ref.S_op.loc['00000_v10','00000_v10'],\n",
    "            #                                      oe_ref.S_op.loc['00000_u10','00000_v10'],\n",
    "            #                                      u10m.values.item(), v10m.values.item())\n",
    "\n",
    "            _, _, w10m, _, tsk,_ = supporting_routines_m.splitX_all_2W(oe_ref.x_op)\n",
    "            _, _, w10m_err, _, tsk_err,_ = supporting_routines_m.splitX_all_2W(oe_ref.x_op_err)\n",
    "\n",
    "            DS_wind['wind'].loc[time_i,acrossT] =  w10m.values.item()\n",
    "            DS_wind['wind_err'].loc[time_i,acrossT] =  w10m_err.values.item()\n",
    "            \n",
    "            print(oe_ref.chiSquareTest()[0][0])\n",
    "            print(oe_ref.chiSquareTest()[0][1])\n",
    "            print(oe_ref.chiSquareTest()[0][2])\n",
    "            print(oe_ref.chiSquareTest()[0][3])\n",
    "            \n",
    "            DS_wind['chiSquareTest1'].loc[time_i,acrossT] = oe_ref.chiSquareTest()[0][0]\n",
    "            DS_wind['chiSquareTest2'].loc[time_i,acrossT] = oe_ref.chiSquareTest()[0][1]\n",
    "            DS_wind['chiSquareTest3'].loc[time_i,acrossT] = oe_ref.chiSquareTest()[0][2]\n",
    "            DS_wind['chiSquareTest4'].loc[time_i,acrossT] = oe_ref.chiSquareTest()[0][3]\n",
    "            \n",
    "            #ssmiRttov.SurfEmisRefl = None\n",
    "            \n",
    "            #print(DS_wind['wind'].loc[time,acrossT].values.item())\n",
    "            #print(DS_wind['wind_err'].loc[time,acrossT].values.item())\n",
    "            \n",
    "            \n",
    "            #gc.collect()\n",
    "            #sleep_and_print_mem(\"After iteration %d\" % i)\n",
    "            \n",
    "print(\"%.2f s , TimeAll\" % (time.time()-startTimeAll))    \n",
    "\n",
    "delayed_obj = DS_wind.chunk(chunks={'time':10}).to_netcdf(\"DS_wind.nc\", compute=False)\n",
    "\n",
    "with ProgressBar():\n",
    "     results = delayed_obj.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DS_wind.chunk(chunks={'time':50}).to_netcdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from dask.diagnostics import ProgressBar\n",
    "\n",
    "# or distributed.progress when using the distributed scheduler\n",
    "delayed_obj = DS_wind.chunk(chunks={'time':10}).to_netcdf(\"DS_wind.nc\", compute=False)\n",
    "\n",
    "with ProgressBar():\n",
    "     results = delayed_obj.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oe_ref.chiSquareTest()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapPlotScat(x,y,data,namefile, mini, maxi, orthoCenter=None):\n",
    "    # Make a Mercator map of the data using Cartopy\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    ortho = ccrs.Orthographic(-120,15) # ccrs.Orthographic(60,-15)\n",
    "    #ortho = ccrs.PlateCarree()\n",
    "    ax = plt.axes(projection=ortho)\n",
    "    \n",
    "    #crs = ccrs.RotatedPole(pole_longitude=177.5, pole_latitude=37.5)\n",
    "    geo = ccrs.Geodetic() # ccrs.PlateCarree() #ccrs.Geodetic()\n",
    "    #crs = ccrs.Orthographic(60,-15)\n",
    "    \n",
    "    ax.add_feature(cartopy.feature.LAND, zorder=0, edgecolor='black',linewidth=0.1)\n",
    "    \n",
    "    xy = ortho.transform_points(geo, x, y)\n",
    "\n",
    "    ax.set_global()\n",
    "    ax.gridlines()    \n",
    "    gl = ax.gridlines(crs=ccrs.PlateCarree(), linewidth=0.07, \n",
    "                      color='black', alpha=0.5, linestyle='--', draw_labels=True)\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER  \n",
    "    \n",
    "\n",
    "    # Plot the air temperature as colored circles and the wind speed as vectors.\n",
    "    im = ax.scatter(\n",
    "        xy[:,0],\n",
    "        xy[:,1],\n",
    "        c=data,\n",
    "        s=0.01, #0.15\n",
    "        marker = \"o\",\n",
    "        cmap=\"viridis\",\n",
    "        #transform=crs,\n",
    "        vmin=mini, vmax=maxi,  # 3,18\n",
    "        #vmin=130, vmax=270,  # 180, 270        \n",
    "    )\n",
    "    fig.colorbar(im).set_label(\"10m Wind Speed, RadEst [m/s]\")\n",
    "    #fig.colorbar(im).set_label(\"Temp. Bright [K]\")\n",
    "    \n",
    "# Use an utility function to add tick labels and land and ocean features to the map.\n",
    "\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    plt.savefig(namefile+'.png', bbox_inches='tight', dpi=450)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_def_world = load_area('areas.yaml', 'worldeqc30km70')# 'worldeqc30km70') # for plots\n",
    "grid_lons_world, grid_lats_world = area_def_world.get_lonlats()\n",
    "\n",
    "swath_radEst = SwathDefinition(lons=DS_wind.lon.values, lats=DS_wind.lat.values)\n",
    "lons_radEst, lats_radEst = swath_radEst.get_lonlats()\n",
    "\n",
    "world_lons, world_lats, world_wind_radEst = \\\n",
    "                           data_reduce.swath_from_lonlat_grid(grid_lons_world, grid_lats_world,\n",
    "                            lons_radEst, lats_radEst, DS_wind.wind.values,\n",
    "                            radius_of_influence=1000)\n",
    "world_lons, world_lats, world_wind_err_radEst = \\\n",
    "                           data_reduce.swath_from_lonlat_grid(grid_lons_world, grid_lats_world,\n",
    "                            lons_radEst, lats_radEst, DS_wind.wind_err.values,\n",
    "                            radius_of_influence=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapPlotScat(world_lons, world_lats, world_wind_radEst,\n",
    "                 'World_wind_RadEst_Plat', 3,18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapPlotScat(world_lons, world_lats, world_wind_err_radEst,\n",
    "                 'World_wind_Err_RadEst_Plat',0.5,1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_TB_frame(BT_scene_env1, area_interest, begin_t, end_t):\n",
    "    \n",
    "    lat_scene1 = supporting_routines_m.generate_masked_array(BT_scene_env1.lat[begin_t:end_t,:],\n",
    "                                                  BT_scene_env1.sft[begin_t:end_t,:], 0, '==', drop= False) \n",
    "    lon_scene1 = supporting_routines_m.generate_masked_array(BT_scene_env1.lon[begin_t:end_t,:],\n",
    "                                                  BT_scene_env1.sft[begin_t:end_t,:], 0, '==', drop= False) \n",
    "    tb_scene1 = supporting_routines_m.generate_masked_array(BT_scene_env1.tb[begin_t:end_t,:,:],\n",
    "                                                  BT_scene_env1.sft[begin_t:end_t,:], 0, '==', drop= False) \n",
    "\n",
    "    grid_lons_interest, grid_lats_interest = area_interest.get_lonlats()\n",
    "\n",
    "    swath_scene1 = SwathDefinition(lons=lon_scene1, lats=lat_scene1)\n",
    "    lons_scene1, lats_scene1 = swath_scene1.get_lonlats()\n",
    "\n",
    "    reduced_lons_scene1, reduced_lats_scene1, reduced_data_scene1 = \\\n",
    "                           data_reduce.swath_from_lonlat_grid(grid_lons_interest, grid_lats_interest,\n",
    "                            lons_scene1, lats_scene1, tb_scene1.values,\n",
    "                            radius_of_influence=3000)\n",
    "\n",
    "    return reduced_lons_scene1, reduced_lats_scene1, reduced_data_scene1\n",
    "    #swath_reduced_scene1 = SwathDefinition(reduced_lons_scene1, reduced_lats_scene1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def defineArea(corners, proj_id, datum):\n",
    "    #corners=parseMeta(data_name)\n",
    "\n",
    "    lat_0 = '{lat_0:5.2f}'.format_map(corners)\n",
    "    lon_0= '{lon_0:5.2f}'.format_map(corners)\n",
    "    lon_bbox = [corners['min_lon'],corners['max_lon']]\n",
    "    lat_bbox = [corners['min_lat'],corners['max_lat']]\n",
    "#    area_dict = dict(datum=datum,lat_0=lat_0,lon_0=lon_0,\n",
    "#                proj=proj_id,units='m')\n",
    "\n",
    "    area_dict = dict(datum=datum,lat_0=-15,lon_0=60,\n",
    "                proj=proj_id,units='m',a=6370997.0,)\n",
    "\n",
    "    prj=pyproj.Proj(area_dict)\n",
    "    x, y = prj(lon_bbox, lat_bbox)\n",
    "    xsize=200\n",
    "    ysize=200\n",
    "    area_id = 'granule'\n",
    "    area_name = 'modis swath 5min granule'\n",
    "    area_extent = (x[0], y[0], x[1], y[1])\n",
    "    print(area_extent)\n",
    "    area_def = AreaDefinition(area_id, area_name, proj_id, \n",
    "                                   area_dict, xsize, ysize,area_extent)\n",
    "    return area_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creation of area of interest:\n",
    "#corners = {\"min_lon\": 25 , \"max_lon\": 75, \"min_lat\": -30 , \"max_lat\": 0, \"lat_0\": 60, \"lon_0\":-15}\n",
    "corners = {\"min_lon\": -95 , \"max_lon\": 20, \"min_lat\": 3 , \"max_lat\": 50, \"lat_0\": 27, \"lon_0\":-57}\n",
    "proj_id = 'eqc'  # eqc\n",
    "datum = 'WGS84'\n",
    "area_interest = defineArea(corners, proj_id, datum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "area_def_world = load_area('areas.yaml', 'worldeqc30km70')# 'worldeqc30km70') # for plots\n",
    "grid_lons_world, grid_lats_world = area_def_world.get_lonlats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeMapAnimScat(BT_scene, BT_attributes, channel, area, \n",
    "                      init_date, nFrames, delta_hours, namefile):\n",
    "    # Make a Mercator map of the data using Cartopy\n",
    "    \n",
    "    import matplotlib.animation as animation\n",
    "\n",
    "    crs = area.to_cartopy_crs()\n",
    "    \n",
    "    #fig2 = plt.subplots(1,2) \n",
    "    fig = plt.figure(frameon=False) #figsize=(8, 6))\n",
    "    fig.add_axes([0,0,1,1])\n",
    "    ax = plt.axes(projection=crs)  \n",
    "    ax.set_global()\n",
    "    gl = ax.gridlines()  \n",
    "    ax.set_title(\"TB \"+namefile)\n",
    "    #ax.set_title(\"Wind Speed \"+namefile)\n",
    "    \n",
    "    ax.add_feature(cartopy.feature.LAND, zorder=0, edgecolor='black') \n",
    "    \n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER \n",
    "\n",
    "\n",
    "    #delta_hours = 12\n",
    "    end_date = init_date + np.timedelta64(delta_hours, 'h') \n",
    "    time_slice = np.where((BT_attributes.time.values>=init_date)&(\n",
    "        BT_attributes.time.values<end_date))\n",
    "    begin_t = time_slice[0][0]  \n",
    "    end_t = time_slice[0][-1]\n",
    "\n",
    "    x, y, data = get_TB_frame(BT_scene, area, begin_t, end_t)\n",
    "    \n",
    "    ims = []\n",
    "    im1 = plt.scatter(\n",
    "            x,\n",
    "            y,\n",
    "            c=data[:,channel],\n",
    "            s=0.15,\n",
    "            cmap=\"viridis\",\n",
    "            #transform=ccrs.PlateCarree(),\n",
    "            #vmin=3, vmax=12     # 180, 270\n",
    "            vmin=130, vmax=270     # 180, 270\n",
    "        ) \n",
    "    \n",
    "    #fig.colorbar(im1).set_label(\"10m Wind Speed [m/s]\")\n",
    "    #fig.colorbar(im1).set_label(\"Temp. Bright. [K]\") \n",
    "    \n",
    "    for i in np.arange(nFrames):\n",
    "\n",
    "        im1 = plt.scatter(\n",
    "            x,\n",
    "            y,\n",
    "            c=data[:,channel],\n",
    "            s=0.15,\n",
    "            cmap=\"viridis\",\n",
    "            transform=ccrs.PlateCarree(),\n",
    "            #vmin=3, vmax=12  # 180, 270\n",
    "            vmin=130, vmax=270  # 180, 270\n",
    "        ) \n",
    "        \n",
    "        ims.append([im1])\n",
    "        init_date = init_date + np.timedelta64(delta_hours, 'h') \n",
    "        end_date = end_date + np.timedelta64(delta_hours, 'h') \n",
    "        time_slice = np.where((BT_attributes.time.values>=init_date)&(\n",
    "            BT_attributes.time.values<end_date))\n",
    "        begin_t = time_slice[0][0]  \n",
    "        end_t = time_slice[0][-1] \n",
    "        x, y, data = get_TB_frame(BT_scene, area, begin_t, end_t)\n",
    "\n",
    "        \n",
    "    im_ani = animation.ArtistAnimation(fig, ims, interval=500, repeat_delay=3000,\n",
    "                                   blit=True)\n",
    "    # To save this second animation with some metadata, use the following command:\n",
    "    # im_ani.save('im.mp4', metadata={'artist':'Guido'})\n",
    "    plt.tight_layout()\n",
    "    im_ani.save(namefile+'.mp4',dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nFrames = 12\n",
    "delta_hours = 12\n",
    "channel = 2\n",
    "namefile = 'env1_22V_12h_F16'\n",
    "timeMapAnimScat(BT_scene, BT_attributes, channel, area_interest, \n",
    "                      init_date, nFrames, delta_hours, namefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Resample swath scene 1 at a world wide scale:\n",
    "\n",
    "result_scene1 = resample_nearest(swath_scene1, tb_scene1.values, area_def_world, \n",
    "                          radius_of_influence=30000, fill_value=np.nan)\n",
    "\n",
    "#result_scene2 = resample_nearest(swath_scene2, tb_scene2.values, area_def_world, \n",
    "#                          radius_of_influence=30000, fill_value=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mask out swath part that intersects the area of interest\n",
    "\n",
    "\n",
    "#reduced_lons_scene2, reduced_lats_scene2, reduced_data_scene2 = \\\n",
    "#                           data_reduce.swath_from_lonlat_grid(grid_lons_interest, grid_lats_interest,\n",
    "#                            lons_scene2, lats_scene2, tb_scene2.values,\n",
    "#                            radius_of_influence=3000)\n",
    "#swath_reduced_scene2 = SwathDefinition(reduced_lons_scene2, reduced_lats_scene2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask out swath part that intersects the area of interest\n",
    "world_lons_scene1, world_lats_scene1, world_data_scene1 = \\\n",
    "                           data_reduce.swath_from_lonlat_grid(grid_lons_world, grid_lats_world,\n",
    "                            lons_scene1, lats_scene1, tb_scene1.values,\n",
    "                            radius_of_influence=3000)\n",
    "swath_world_scene1 = SwathDefinition(reduced_lons_scene1, reduced_lats_scene1)\n",
    "\n",
    "world_lons_scene2, world_lats_scene2, world_data_scene2 = \\\n",
    "                           data_reduce.swath_from_lonlat_grid(grid_lons_world, grid_lats_world,\n",
    "                            lons_scene2, lats_scene2, tb_scene2.values,\n",
    "                            radius_of_influence=3000)\n",
    "swath_world_scene2 = SwathDefinition(reduced_lons_scene2, reduced_lats_scene2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Resample swath data into a grid in the area of interest \n",
    "result_reduced_scene1 = resample_nearest(swath_reduced_scene1, reduced_data_scene1, area_interest, \n",
    "                                  radius_of_influence=30000, fill_value=None)\n",
    "\n",
    "result_reduced_scene2 = resample_nearest(swath_reduced_scene2, reduced_data_scene2, area_interest, \n",
    "                                  radius_of_influence=30000, fill_value=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapArea('mapArea0', area_def_world)\n",
    "mapArea('mapArea01', area_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chann = 0\n",
    "# Plot resampled (grid version) scenes:\n",
    "basicMapPlot(result_scene1[:,:,chann],'scene1'+str(chann), area_def_world)  # map of the whole world, grid\n",
    "basicMapPlot(result_reduced_scene1[:,:,chann],\n",
    "             'scene1_reduced'+str(chann), area_interest)  # map only the area of interest, grid\n",
    "\n",
    "basicMapPlot(result_scene2[:,:,chann],'scene2'+str(chann), area_def_world)  # map of the whole world, grid\n",
    "basicMapPlot(result_reduced_scene2[:,:,chann],\n",
    "             'scene2_reduced'+str(chann), area_interest)  # map only the area of interest, grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot in area of interest, Plate Carree projection\n",
    "\n",
    "chann = 0\n",
    "# Plot original swath pixels:\n",
    "basicMapPlotScat(reduced_lons_scene1, reduced_lats_scene1, reduced_data_scene1[:,chann],\n",
    "                 'scene1_scatt_PCarr_19H', area_interest, )\n",
    "chann = 1\n",
    "# Plot original swath pixels:\n",
    "basicMapPlotScat(reduced_lons_scene1, reduced_lats_scene1, reduced_data_scene1[:,chann],\n",
    "                 'scene1_scatt_PCarr_19V', area_interest, )\n",
    "chann = 2\n",
    "# Plot original swath pixels:\n",
    "basicMapPlotScat(reduced_lons_scene1, reduced_lats_scene1, reduced_data_scene1[:,chann],\n",
    "                 'scene1_scatt_PCarr_22V', area_interest, )\n",
    "#chann = 1\n",
    "#basicMapPlotScat(reduced_lons_scene2, reduced_lats_scene2, reduced_data_scene2[:,chann],\n",
    "#                 'scene2_scatt_PCarr_91V', area_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = Path('/nobackup/users/echeverr/fortran_tests/netcdf/following_Edouard/imgs/ch19H')\n",
    "images = list(image_path.glob('*.png'))\n",
    "image_list = []\n",
    "for file_name in images:\n",
    "    image_list.append(imageio.imread(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.mimwrite('animated_from_images.gif', image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot in world area, Orthographic projection\n",
    "\n",
    "chann = 2\n",
    "# Plot original swath pixels:\n",
    "basicMapPlotScat1(reduced_lons_scene1, reduced_lats_scene1, reduced_data_scene1[:,chann],\n",
    "                 'world_scene1_scatt_Orth_22V', area_interest)\n",
    "#chann = 3\n",
    "#basicMapPlotScat1(reduced_lons_scene2, reduced_lats_scene2, reduced_data_scene2[:,chann],\n",
    "#                 'world_scene1_scatt_Orth_91H', area_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot original swath pixels:\n",
    "chann = 2\n",
    "basicMapPlotScat1(world_lons_scene1, world_lats_scene1, world_data_scene1[:,chann],\n",
    "                 'scene1_scatt_Orth_world_22V', area_def_world)\n",
    "chann = 3\n",
    "basicMapPlotScat1(world_lons_scene2, world_lats_scene2, world_data_scene2[:,chann],\n",
    "                 'scene1_scatt_Orth_world_91H', area_def_world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def basicMapPlot(result,namefile, area):\n",
    "    crs = area.to_cartopy_crs()\n",
    "    fig, ax = plt.subplots(figsize=(13, 3))\n",
    "    ax= plt.axes(projection=crs)\n",
    "    #ax.background_img(name='BM', resolution='high') \n",
    "    ax.coastlines();\n",
    "    #ax.stock_img();\n",
    "    ax.grid(True)\n",
    "    #ax.set_xlabel('Longitude [deg]')\n",
    "    #ax.set_ylabel('Latitude [deg]')\n",
    "\n",
    "    #gl = ax.gridlines(crs=ccrs.Orthographic(), linewidth=0.1, \n",
    "    #                  color='black', alpha=0.5, linestyle='--', draw_labels=True)\n",
    "    #gl.xlabels_top = False\n",
    "    #gl.ylabels_left = False\n",
    "    #gl.ylabels_right=True\n",
    "    #gl.xlines = True\n",
    "    #gl.xlocator = mticker.FixedLocator([70, 75, 80, 85])\n",
    "    #gl.ylocator = mticker.FixedLocator([-5, -3, -1, 1, 3])\n",
    "    #gl.xformatter = LONGITUDE_FORMATTER\n",
    "    #gl.yformatter = LATITUDE_FORMATTER\n",
    "\n",
    "    im = ax.imshow(result, transform=crs, extent=crs.bounds, origin='upper', cmap='jet', vmin=150, vmax=250)\n",
    "    fig.colorbar(im,ax=ax) \n",
    "    plt.savefig(namefile+'.png', bbox_inches='tight', dpi=150)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def basicMapPlotScat(x,y,data,namefile, area):\n",
    "    # Make a Mercator map of the data using Cartopy\n",
    "    \n",
    "    crs = area.to_cartopy_crs()\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    #plt.figure(figsize=(8, 6))\n",
    "    ax = plt.axes(projection=crs)   \n",
    "    ax.add_feature(cartopy.feature.LAND, zorder=0, edgecolor='black')\n",
    "    ax.set_global()\n",
    "    ax.gridlines()        \n",
    "    ax.set_title(\"TB\")\n",
    "    \n",
    "    gl = ax.gridlines(crs=ccrs.PlateCarree(), linewidth=0.1, \n",
    "                      color='black', alpha=0.5, linestyle='--', draw_labels=True)\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER    \n",
    "\n",
    "    # Plot the air temperature as colored circles and the wind speed as vectors.\n",
    "    im = ax.scatter(\n",
    "        x,\n",
    "        y,\n",
    "        c=data,\n",
    "        s=0.15,\n",
    "        cmap=\"viridis\",\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        #vmin=3, vmax=18         #180, 270\n",
    "        vmin=130, vmax=270         #180, 270\n",
    "    )\n",
    "    fig.colorbar(im).set_label(\"Brightness temperature [K]\")\n",
    "    \n",
    "# Use an utility function to add tick labels and land and ocean features to the map.\n",
    "\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    plt.savefig(namefile+'.png', bbox_inches='tight', dpi=150)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mapArea(namefile, area):\n",
    "\n",
    "    crs = area.to_cartopy_crs()\n",
    "    fig, ax = plt.subplots(figsize=(13, 3))\n",
    "    ax= plt.axes(projection=crs)\n",
    "    \n",
    "    #gl = ax.gridlines(crs=ccrs.Orthographic(), linewidth=0.1, \n",
    "    #                  color='black', alpha=0.5, linestyle='--', draw_labels=True)\n",
    "\n",
    "    #gl.xformatter = LONGITUDE_FORMATTER\n",
    "    #gl.yformatter = LATITUDE_FORMATTER\n",
    "    \n",
    "    ax.coastlines(linewidth=0.5)   \n",
    "    #ax.set_global() \n",
    "    plt.savefig(namefile+'.png', bbox_inches='tight', dpi=300)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chann = 0\n",
    "#basicMapAnimScat(reduced_lons_scene2, reduced_lats_scene2, reduced_data_scene2[:,chann],\n",
    "#                 'scene1_scatt'+str(chann), area_interest)\n",
    "\n",
    "nFrames = 150\n",
    "start_frame = 0\n",
    "nAcrossSwathFrame = 180\n",
    "\n",
    "chann = 0\n",
    "basicMapAnimScat(reduced_lons_scene2, reduced_lats_scene2, reduced_data_scene2[:,chann],\n",
    "                 'An_scene1_scatt_Orth_red_19H', area_interest, \n",
    "                  nFrames, start_frame, nAcrossSwathFrame)\n",
    "\n",
    "chann = 2\n",
    "basicMapAnimScat(reduced_lons_scene2, reduced_lats_scene2, reduced_data_scene2[:,chann],\n",
    "                 'An_scene1_scatt_Orth_red_91V', area_interest, \n",
    "                  nFrames, start_frame, nAcrossSwathFrame)\n",
    "\n",
    "chann = 2\n",
    "basicMapAnimScat(reduced_lons_scene2, reduced_lats_scene2, reduced_data_scene2[:,chann],\n",
    "                 'An_scene1_scatt_Orth_red_22V', area_interest, \n",
    "                  nFrames, start_frame, nAcrossSwathFrame)\n",
    "\n",
    "chann = 3\n",
    "basicMapAnimScat(reduced_lons_scene2, reduced_lats_scene2, reduced_data_scene2[:,chann],\n",
    "                 'An_scene1_scatt_Orth_red_91H', area_interest, \n",
    "                  nFrames, start_frame, nAcrossSwathFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def basicMapAnimScat(x,y,data,namefile, area, \n",
    "                      nFrames, start_frame, nAcrossSwathFrame):\n",
    "    # Make a Mercator map of the data using Cartopy\n",
    "    \n",
    "    import matplotlib.animation as animation\n",
    "\n",
    "    crs = area.to_cartopy_crs()\n",
    "    \n",
    "    #fig2 = plt.subplots(1,2) \n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = plt.axes(projection=crs)  \n",
    "    ax.set_global()\n",
    "    gl = ax.gridlines()  \n",
    "    #ax.set_title(\"TB \"+namefile)\n",
    "    ax.set_title(\"Wind Speed \"+namefile)\n",
    "    \n",
    "    ax.add_feature(cartopy.feature.LAND, zorder=0, edgecolor='black')\n",
    "   \n",
    "    #gl0 = ax.gridlines(crs=ccrs.PlateCarree(), linewidth=0.1, \n",
    "    #                  color='black', alpha=0.5, linestyle='--', draw_labels=True)\n",
    "\n",
    "    #gl0.xformatter = LONGITUDE_FORMATTER\n",
    "    #gl0.yformatter = LATITUDE_FORMATTER \n",
    "    \n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER \n",
    "    \n",
    "    start_ = start_frame\n",
    "    end_ = nAcrossSwathFrame\n",
    "    \n",
    "    ims = []\n",
    "    x2 = x[start_:end_]\n",
    "    y2 = y[start_:end_]\n",
    "    data2_0 = data[start_:end_]\n",
    "    #data2_2 = data[start_:end_,2]\n",
    "\n",
    "    im1 = plt.scatter(\n",
    "            x2,\n",
    "            y2,\n",
    "            c=data2_0,\n",
    "            s=0.15,\n",
    "            cmap=\"viridis\",\n",
    "            #transform=ccrs.PlateCarree(),\n",
    "            vmin=3, vmax=12     # 180, 270\n",
    "            #vmin=130, vmax=270     # 180, 270\n",
    "        ) \n",
    "    fig.colorbar(im1).set_label(\"10m Wind Speed [m/s]\")\n",
    "    #fig.colorbar(im1).set_label(\"Temp. Bright. [K]\") \n",
    "    for i in np.arange(nFrames):\n",
    "        #ims.append((plt.pcolor(x, y, base + add, norm=plt.Normalize(0, 30)),))\n",
    "\n",
    "        im1 = plt.scatter(\n",
    "            x2,\n",
    "            y2,\n",
    "            c=data2_0,\n",
    "            s=0.15,\n",
    "            cmap=\"viridis\",\n",
    "            transform=ccrs.PlateCarree(),\n",
    "            vmin=3, vmax=12  # 180, 270\n",
    "            #vmin=130, vmax=270  # 180, 270\n",
    "        ) \n",
    "\n",
    "        ims.append([im1])\n",
    "      \n",
    "        \n",
    "        start_ +=nAcrossSwathFrame\n",
    "        end_ +=nAcrossSwathFrame\n",
    "        x2 = np.append(x2,x[start_:end_])\n",
    "        y2 = np.append(y2,y[start_:end_])\n",
    "        data2_0 = np.append(data2_0,data[start_:end_])\n",
    "        #data2_2 = np.append(data2_2,data[start_:end_,2])\n",
    "\n",
    "        \n",
    "    im_ani = animation.ArtistAnimation(fig, ims, interval=50, repeat_delay=3000,\n",
    "                                   blit=True)\n",
    "    # To save this second animation with some metadata, use the following command:\n",
    "    # im_ani.save('im.mp4', metadata={'artist':'Guido'})\n",
    "    im_ani.save(namefile+'_bar.mp4',dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BT_scene_env2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def basicMapPlotScat1(x,y,data,namefile, area):\n",
    "    # Make a Mercator map of the data using Cartopy\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    ortho = ccrs.Orthographic(60,-15)\n",
    "    ax = plt.axes(projection=ortho)\n",
    "    \n",
    "    crs = ccrs.RotatedPole(pole_longitude=177.5, pole_latitude=37.5)\n",
    "    geo = ccrs.Geodetic()\n",
    "    #crs = ccrs.Orthographic(60,-15)\n",
    "    \n",
    "    ax.add_feature(cartopy.feature.LAND, zorder=0, edgecolor='black')\n",
    "    \n",
    "    xy = ortho.transform_points(geo, x, y)\n",
    "\n",
    "    ax.set_global()\n",
    "    ax.gridlines()    \n",
    "    \n",
    "    #ax.set_title(\"TB\")\n",
    "    #ax.coastlines() \n",
    "    # Plot the air temperature as colored circles and the wind speed as vectors.\n",
    "    im = ax.scatter(\n",
    "        xy[:,0],\n",
    "        xy[:,1],\n",
    "        c=data,\n",
    "        s=0.15,\n",
    "        cmap=\"viridis\",\n",
    "        #transform=crs,\n",
    "        #vmin=3, vmax=18,  # 180, 270\n",
    "        vmin=130, vmax=270,  # 180, 270        \n",
    "    )\n",
    "    #fig.colorbar(im).set_label(\"10m Wind Speed, HOAPS [m/s]\")\n",
    "    fig.colorbar(im).set_label(\"Temp. Bright [K]\")\n",
    "    \n",
    "# Use an utility function to add tick labels and land and ocean features to the map.\n",
    "\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    plt.savefig(namefile+'.png', bbox_inches='tight', dpi=300)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nFrames = 1200\n",
    "start_frame = 0\n",
    "nAcrossSwathFrame = 180\n",
    "\n",
    "chann = 0\n",
    "basicMapAnimScat1(world_lons_scene1, world_lats_scene1, world_data_scene1[:,chann],\n",
    "                 'An_scene1_scatt_Orth_world_19H', area_interest, \n",
    "                  nFrames, start_frame, nAcrossSwathFrame)\n",
    "\n",
    "chann = 2\n",
    "basicMapAnimScat1(world_lons_scene2, world_lats_scene2, world_data_scene2[:,chann],\n",
    "                 'An_scene1_scatt_Orth_world_91V', area_interest, \n",
    "                  nFrames, start_frame, nAcrossSwathFrame)\n",
    "\n",
    "chann = 2\n",
    "basicMapAnimScat1(world_lons_scene1, world_lats_scene1, world_data_scene1[:,chann],\n",
    "                 'An_scene1_scatt_Orth_world_22V', area_interest, \n",
    "                  nFrames, start_frame, nAcrossSwathFrame)\n",
    "\n",
    "chann = 3\n",
    "basicMapAnimScat1(world_lons_scene2, world_lats_scene2, world_data_scene2[:,chann],\n",
    "                 'An_scene1_scatt_Orth_world_91H', area_interest, \n",
    "                  nFrames, start_frame, nAcrossSwathFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def basicMapAnimScat1(x,y,data,namefile, area, \n",
    "                      nFrames, start_frame, nAcrossSwathFrame):\n",
    "    # Make a Mercator map of the data using Cartopy\n",
    "    \n",
    "    import matplotlib.animation as animation\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    ortho = ccrs.Orthographic(-39,18) #ccrs.Orthographic(60,-15)\n",
    "    ax = plt.axes(projection=ortho)\n",
    "    \n",
    "    crs = ccrs.RotatedPole(pole_longitude=177.5, pole_latitude=37.5)\n",
    "    geo = ccrs.Geodetic()\n",
    "    \n",
    "    ax.add_feature(cartopy.feature.LAND, zorder=0, edgecolor='black')\n",
    "    \n",
    "    xy = ortho.transform_points(geo, x, y)\n",
    "\n",
    "    ax.set_global()\n",
    "    ax.gridlines()        \n",
    "       \n",
    "    ax.set_title(\"Wind Speed \"+namefile) \n",
    "    #ax.set_title(\"Temperature Brightness \"+namefile) \n",
    "    \n",
    "    start_ = start_frame\n",
    "    end_ = nAcrossSwathFrame\n",
    "    \n",
    "    ims = []\n",
    "    x2 = xy[start_:end_,0]\n",
    "    y2 = xy[start_:end_,1]\n",
    "    data2_0 = data[start_:end_]\n",
    "    #data2_2 = data[start_:end_,2]\n",
    "\n",
    "    im1 = plt.scatter(\n",
    "            x2,\n",
    "            y2,\n",
    "            c=data2_0,\n",
    "            s=0.15,\n",
    "            cmap=\"viridis\",\n",
    "            #transform=ccrs.PlateCarree(),\n",
    "            vmin=3, vmax=18  # 180, 250\n",
    "            #vmin=130, vmax=270   # 180, 270 TB\n",
    "        ) \n",
    "    fig.colorbar(im1).set_label(\"10m Wind Speed [m/s]\")\n",
    "    #fig.colorbar(im1).set_label(\"Temp. Bright. [K]\") \n",
    "    for i in np.arange(nFrames):\n",
    "        #ims.append((plt.pcolor(x, y, base + add, norm=plt.Normalize(0, 30)),))\n",
    "\n",
    "        #plt.tight_layout()\n",
    "        im1 = plt.scatter(\n",
    "            x2,\n",
    "            y2,\n",
    "            c=data2_0,\n",
    "            s=0.15,\n",
    "            cmap=\"viridis\",\n",
    "            #transform=ccrs.PlateCarree(),\n",
    "            vmin=3, vmax=18   # 180, 270 TB\n",
    "            #vmin=130, vmax=270   # 180, 270 TB\n",
    "        ) \n",
    "\n",
    "        ims.append([im1])\n",
    "      \n",
    "        \n",
    "        start_ +=nAcrossSwathFrame\n",
    "        end_ +=nAcrossSwathFrame\n",
    "        x2 = np.append(x2,xy[start_:end_,0])\n",
    "        y2 = np.append(y2,xy[start_:end_,1])\n",
    "        data2_0 = np.append(data2_0,data[start_:end_])\n",
    "        #data2_2 = np.append(data2_2,data[start_:end_,2])\n",
    "\n",
    "        \n",
    "    im_ani = animation.ArtistAnimation(fig, ims, interval=30, repeat_delay=3000,\n",
    "                                   blit=True)\n",
    "    # To save this second animation with some metadata, use the following command:\n",
    "    # im_ani.save('im.mp4', metadata={'artist':'Guido'})\n",
    "    im_ani.save(namefile+'.mp4',dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
